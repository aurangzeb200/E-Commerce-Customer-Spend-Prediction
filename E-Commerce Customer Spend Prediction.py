# -*- coding: utf-8 -*-
"""1st Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BTPIvWARjR3at7d3lofd81R9FnNhO3ny
"""

import pandas as pd
customer_data = pd.read_csv("/content/E-commerce Customer Behavior - Sheet1.csv")

customer_data.head()

customer_data.describe()

"""**By analyzing the data through various charts and graphs, it was observed that customers with low spending and those holding Silver or Bronze membership types are unsatisfied. These two features were chosen for analysis as they have a significant impact on the satisfaction level of customers.**"""

customer_data[customer_data["Satisfaction Level"].isnull()]

"""**We can also apply other methods like logistic regression but here there are only two null values so we fill values by manually analyzing data.**"""

customer_data['Satisfaction Level'] = customer_data['Satisfaction Level'].fillna("Unsatisfied")

customer_data

customer_data.describe()

"""Spend Category is made by the column Total Spend by dividing it according to 33 percentile 66 and 99"""

bins=[0,660.3,830.9,float('inf')]
labels=["Low Spend","Medium Spend","High Spend"]
customer_data["Spend Category"]=pd.cut(customer_data['Total Spend'],bins=bins,labels=labels)

customer_data

"""# Exploratory Data Analysis (EDA)"""

customer_data.columns

"""# Membership Type vs Satisfaction Level"""

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(rc={'figure.figsize':(10,6)})
sns.countplot(x=customer_data["Membership Type"],hue=customer_data["Satisfaction Level"])
plt.xlabel("Membership Type")
plt.ylabel("Count")
plt.title("Membership Type vs Satisfaction Level")
plt.show()

"""# Gender vs City vs Spend Category"""

high_spend_customers = customer_data.query("`Spend Category` == 'High Spend'")
medium_spend_customers = customer_data.query("`Spend Category` == 'Medium Spend'")
low_spend_customers = customer_data.query("`Spend Category` == 'Low Spend'")

forplot = high_spend_customers.groupby(["Gender","City"]).size()
modplot = medium_spend_customers.groupby(["Gender","City"]).size()
lowplot = low_spend_customers.groupby(["Gender","City"]).size()

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
a = sns.barplot(x=forplot.index.get_level_values("Gender"),
                y=forplot.values,
                hue=forplot.index.get_level_values("City"))

for container in a.containers:
    a.bar_label(container)

plt.xlabel("Gender")
plt.ylabel("Number of Customers")
plt.title("High Spend Customers by Gender and City")
plt.show()

plt.figure(figsize=(10,6))
a = sns.barplot(x=modplot.index.get_level_values("Gender"),
                y=modplot.values,
                hue=modplot.index.get_level_values("City"))

for container in a.containers:
    a.bar_label(container)

plt.xlabel("Gender")
plt.ylabel("Number of Customers")
plt.title("Medium Spend Customers by Gender and City")
plt.show()

plt.figure(figsize=(10,6))
a = sns.barplot(x=lowplot.index.get_level_values("Gender"),
                y=lowplot.values,
                hue=lowplot.index.get_level_values("City"))

for container in a.containers:
    a.bar_label(container)

plt.xlabel("Gender")
plt.ylabel("Number of Customers")
plt.title("Low Spend Customers by Gender and City")
plt.show()

"""We can see from the above graph that:

1.   High spend customers are both males and females and from NewYork and San Francisco and also mostly females are from NewYork but most of men are from San Fransico
2.   Medium spend customers are mostly males from Miami and Los angeles
3.   Low spend customers are mostly females from chicago and hoston

# Spend Category vs Satisfaction Level:
"""

ok = customer_data.groupby(['Satisfaction Level','Spend Category']).size()

sns.set(rc={'figure.figsize': (10, 6)})
a = sns.barplot(x=ok.index.get_level_values("Spend Category"),
                 y=ok.values,
                 hue=ok.index.get_level_values("Satisfaction Level"))

for container in a.containers:
    a.bar_label(container)

plt.xlabel("Satisfaction Level")
plt.ylabel("Number of Customers")
plt.title("Customers by Satisfaction Level and Spend Category")
plt.show()

"""1. High spend customers are all satisfied.  
2. Medium spend customers have very few satisfied, with some neutral and some unsatisfied.  
3. Low spend customers have many unsatisfied, with some neutral.

# Spend Category vs Satisfaction Level vs Gender
"""

forplot = high_spend_customers.groupby(["Gender","Satisfaction Level"]).size()
modplot = medium_spend_customers.groupby(["Gender","Satisfaction Level"]).size()
lowplot = low_spend_customers.groupby(["Gender","Satisfaction Level"]).size()

plt.figure(figsize=(10, 6))
a = sns.barplot(x=forplot.index.get_level_values("Gender"),
                y=forplot.values,
                hue=forplot.index.get_level_values("Satisfaction Level"))

for container in a.containers:
    a.bar_label(container)

plt.xlabel("Gender")
plt.ylabel("Number of Customers")
plt.title("High Spend Customers by Gender and Satisfaction Level")
plt.show()

plt.figure(figsize=(10,6))
a = sns.barplot(x=modplot.index.get_level_values("Gender"),
                y=modplot.values,
                hue=modplot.index.get_level_values("Satisfaction Level"))

for container in a.containers:
    a.bar_label(container)

plt.xlabel("Gender")
plt.ylabel("Number of Customers")
plt.title("Medium Spend Customers by Gender and Satisfaction Level")
plt.show()

plt.figure(figsize=(10,6))
a = sns.barplot(x=lowplot.index.get_level_values("Gender"),
                y=lowplot.values,
                hue=lowplot.index.get_level_values("Satisfaction Level"))

for container in a.containers:
    a.bar_label(container)

plt.xlabel("Gender")
plt.ylabel("Number of Customers")
plt.title("Low Spend Customers by Gender and Satisfaction Level")
plt.show()

"""1. Both males and females of High spend customers are all satisfied.  
2. In Medium spend customers mostly males are unsatisfied and neutral.
3. In Low spend customers mostly females are unsatisfied and neutral.

# Top cities by Total Spend
"""

city_spend = customer_data.groupby(["City"],as_index=False)['Total Spend'].sum().sort_values(by="Total Spend",ascending=False).head(10)
city_spend['Total Spend'] = city_spend['Total Spend'].astype(int)

sns.set(rc={'figure.figsize':(10,6)})
a=sns.barplot(x="City",y="Total Spend",data=city_spend)
for container in a.containers:
    a.bar_label(container)

plt.xlabel("Cities")
plt.ylabel("Total Spend")
plt.title("Top Cities by Total Spend")
plt.show()

"""San Francisco,New York, Los Angeles have high spend customers

# Age Specific Targeting
"""

age_spend = customer_data.groupby(["Age"],as_index=False)['Total Spend'].sum().sort_values(by="Total Spend",ascending=False).head(10)
age_spend['Total Spend'] = age_spend['Total Spend'].astype(int)

sns.set(rc={'figure.figsize':(10,6)})
a=sns.barplot(x=age_spend["Age"],y=age_spend["Total Spend"])
for container in a.containers:
    a.bar_label(container)

plt.xlabel("Ages")
plt.ylabel("Total Spend")
plt.title("Ages by Total Spend")
plt.show()

"""Hence most customers age are 30 and then 28.
The majority of customers are aged 28, 30, 31, and 32.

# Top Spender's Customer ids
"""

customer_spend = customer_data.groupby(["Customer ID"],as_index=False)['Total Spend'].sum().sort_values(by="Total Spend",ascending=False).head(10)
customer_spend['Total Spend'] = customer_spend['Total Spend'].astype(int)

sns.set(rc={'figure.figsize':(10,6)})
a=sns.barplot(x=customer_spend["Customer ID"],y=customer_spend["Total Spend"].head(10))
for container in a.containers:
    a.bar_label(container)

plt.xlabel("Customer IDS")
plt.ylabel("Total Spend")
plt.title("Customer Ids by Total Spend")
plt.show()

"""# Discounts vs Spending vs Satisfaction"""

crosstab = pd.crosstab([customer_data['Discount Applied'], customer_data['Spend Category']], customer_data['Satisfaction Level'])

sns.set(rc={'figure.figsize':(10,6)})
sns.heatmap(crosstab, annot=True, cmap='Blues')
plt.title('Customers by Spend Category, Discount Applied, and Satisfaction Level')
plt.xlabel('Satisfaction Level')
plt.ylabel('Discount Applied and Spend Category')
plt.show()

"""Hence Low spend and medium spend customers on which discount is applied are unsatisfied

# Purchase Frequency
"""

sns.set(rc={'figure.figsize':(10,6)})
sns.histplot(customer_data['Days Since Last Purchase'])
plt.xlabel('Days Since Last Purchase')
plt.ylabel('Frequency')
plt.title('Distribution of Days Since Last Purchase')
plt.show()

bins=[0,25,40,55,float('inf')]
labels=["Frequent Buyers","Regular Buyers","Occasional Buyers","Rare Buyers"]
customer_data["Buyer's Type"]=pd.cut(customer_data['Days Since Last Purchase'],bins=bins,labels=labels)

sns.set(rc={'figure.figsize':(10,6)})
a= sns.countplot(x=customer_data["Buyer's Type"])
for container in a.containers:
    a.bar_label(container)
plt.xlabel('Buyer Type')
plt.ylabel('Count')
plt.title('Customer Buyer Type')
plt.show()

"""From histogram(first plot) we can see that mostly customers are purchasing right now

Segment customers based on their purchase frequency.

1. Frequent Buyers: Purchase every 0-25 days
2. Regular Buyers: Purchase every 25-40 days
3. Occasional Buyers: Purchase every 40-55 days
4. Rare Buyers: Purchase every 55+ days

# Model Building
"""

bins=[0,25,40,55,float('inf')]
labels=["Frequent Buyers","Regular Buyers","Occasional Buyers","Rare Buyers"]
customer_data["Buyer's Type"]=pd.cut(customer_data['Days Since Last Purchase'],bins=bins,labels=labels)

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
customer_data['Spend Category']=le.fit_transform(customer_data['Spend Category'])
customer_data['Membership Type']=le.fit_transform(customer_data['Membership Type'])
customer_data['Satisfaction Level']=le.fit_transform(customer_data['Satisfaction Level'])

encode = pd.get_dummies(customer_data,columns=['City','Gender','Discount Applied',"Buyer's Type"])

encode = encode[['City_Chicago', 'City_Houston',
       'City_Los Angeles', 'City_Miami', 'City_New York', 'City_San Francisco',
       'Gender_Female', 'Gender_Male', 'Discount Applied_False',
       'Discount Applied_True', "Buyer's Type_Frequent Buyers",
       "Buyer's Type_Regular Buyers", "Buyer's Type_Occasional Buyers",
       "Buyer's Type_Rare Buyers"]].astype(int)

customer_data.drop(columns=['City','Gender','Discount Applied',"Buyer's Type"],inplace=True)

customer_data = pd.concat([customer_data,encode],axis=1)

customer_data.info()

pd.set_option('display.max_columns',None)
customer_data

customer_data.drop(columns="Customer ID",axis=1,inplace=True)

X = customer_data.drop(columns=['Total Spend'])
y = customer_data['Total Spend']

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X , y , test_size=0.15,random_state=101)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train_transform = sc.fit_transform(X_train)
X_test_transform = sc.transform(X_test)

from sklearn.linear_model import Lasso
from sklearn.model_selection import GridSearchCV
lr = Lasso()
para_grid={
    'alpha':[0.1,1,10,100]
}
grid_search=GridSearchCV(lr,para_grid,cv=5)
grid_search.fit(X_train_transform,y_train)

y_pred = grid_search.predict(X_test_transform)
print(y_pred)

import seaborn as sns
  import matplotlib.pyplot as plt
  sns.scatterplot(x=y_test, y=y_pred, color='blue', label='Actual Data points')
  plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', label='Ideal Line')
  plt.legend()
  plt.show()

import numpy as np
results = np.column_stack((y_test, y_pred))

print("Actual Values  |  Predicted Values")
print("-----------------------------")
for actual, predicted in results:
    print(f"{actual:14.2f} |  {predicted:12.2f}")

ok=y_pred-y_test

sns.set(rc={'figure.figsize':(10,6)})
sns.histplot(ok,bins=20,kde=True)
plt.xlabel("Residuals")
plt.ylabel("Frequency")
plt.title("Distribution of Residuals")
plt.show()

from sklearn.metrics import mean_squared_error
lr_mse = mean_squared_error(y_test, y_pred)
lr_rmse = np.sqrt(lr_mse)
print("RMSE:", lr_rmse)

def correlation(correlation_matrix):
  sns.set(rc={'figure.figsize':(15,6)})
  sns.heatmap(correlation_matrix,annot=True,cmap='coolwarm')
  plt.title("Correlation Matrix")
  plt.show()
  features=[]
  high_corr_pairs = []
  threshold=0.95
  # Iterate over the correlation matrix to find high correlations
  for i in range(len(correlation_matrix.columns)):
    for j in range(i):
        if abs(correlation_matrix.iloc[i, j]) > threshold:
            feature_1 = correlation_matrix.columns[i]
            feature_2 = correlation_matrix.columns[j]
            high_corr_pairs.append((feature_1, feature_2, correlation_matrix.iloc[i, j]))

# Display the results
  print("High Correlation Pairs (Threshold > {}):".format(threshold))
  for pair in high_corr_pairs:
    print(f"Features: {pair[0]} and {pair[1]} | Correlation: {pair[2]}")

  ok=[]
  for pair in high_corr_pairs:
    ok.append(pair[0])
  print(set(ok))



def drop_features(data,features):
  features = list(features)
  data.drop(columns=features, axis=1, inplace=True)
  return data


X_corr = X.corr()
features_to_drop = correlation(X_corr)
# print(features_to_drop)
# X = drop_features(X, features_to_drop)
# print(X)

import numpy as np
from sklearn.metrics import mean_squared_error,r2_score
from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(random_state=42)

para_grid={
    'n_estimators':[125],
    'max_depth':[None],
    'min_samples_split':[10],
    'min_samples_leaf':[1]
}


opt_rf = GridSearchCV(rf,para_grid,cv=5, scoring='neg_mean_squared_error' ,n_jobs=-1)

opt_rf.fit(X_train_transform, y_train)
opt_rf_predict = opt_rf.predict(X_test_transform)


results = np.column_stack((y_test, opt_rf_predict))
print("Actual Values  |  Predicted Values")
print("-----------------------------")
for actual, predicted in results:
    print(f"{actual:14.2f} |  {predicted:12.2f}")

rf_mse = mean_squared_error(y_test, opt_rf_predict)
rf_rmse = np.sqrt(rf_mse)

print("RMSE:", rf_rmse)
print("MSE:", rf_mse)
print(opt_rf.best_params_)



from sklearn.ensemble import GradientBoostingRegressor

gbr = GradientBoostingRegressor(n_estimators=100, random_state=42)
gbr.fit(X_train_transform, y_train)

y_gbr_predict = gbr.predict(X_test_transform)

gbr_mse = mean_squared_error(y_test, y_gbr_predict)
gbr_rmse = np.sqrt(gbr_mse)

gbr_results = np.column_stack((y_test, y_gbr_predict))
print("\nGradient Boosting Regressor - Actual vs Predicted Values")
print("------------------------------------------------------")
for actual, predicted in gbr_results:
    print(f"{actual:14.2f} |  {predicted:12.2f}")

from sklearn.tree import DecisionTreeRegressor

dt = DecisionTreeRegressor(random_state=42)
dt.fit(X_train_transform, y_train)

y_dt_predict = dt.predict(X_test_transform)

dt_mse = mean_squared_error(y_test, y_dt_predict)
dt_rmse = np.sqrt(dt_mse)

dt_results = np.column_stack((y_test, y_dt_predict))
print("\nDecision Tree Regressor - Actual vs Predicted Values")
print("---------------------------------------------------")
for actual, predicted in dt_results:
    print(f"{actual:14.2f} |  {predicted:12.2f}")

print("Linear Regression RMSE:", lr_rmse)
print("Random Forest RMSE:", rf_rmse)
print("Gradient Boosting RMSE:", gbr_rmse)
print("Decision Tree RMSE:", dt_rmse)

print("Linear Regression MSE:", lr_mse)
print("Random Forest MSE:", rf_mse)
print("Gradient Boosting MSE:", gbr_mse)
print("Decision Tree MSE:", dt_mse)